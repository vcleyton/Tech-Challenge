# ğŸ“š Books Tech Challenge

API RESTful para ingestÃ£o, persistÃªncia e exposiÃ§Ã£o de dados de livros, com foco em **engenharia de dados** e **Machine Learning**. O projeto demonstra boas prÃ¡ticas de arquitetura, documentaÃ§Ã£o e seguranÃ§a, estando preparado para evoluÃ§Ã£o em ambientes de produÃ§Ã£o.

---

## âœ¨ VisÃ£o Geral

O **Books Tech Challenge** Ã© uma API desenvolvida em **Python** com **Flask** e **Flask-RESTX**, responsÃ¡vel por fornecer dados de uma coleÃ§Ã£o fictÃ­cia de livros. A soluÃ§Ã£o contempla desde a ingestÃ£o (scraping simulado) atÃ© o consumo por aplicaÃ§Ãµes, dashboards e pipelines de ML.

### Principais funcionalidades

* ğŸ“¥ **IngestÃ£o de dados** (scraping simulado)
* ğŸ—„ï¸ **PersistÃªncia** em banco SQLite
* ğŸ” **AutenticaÃ§Ã£o JWT** para rotas sensÃ­veis
* ğŸ“Š **EstatÃ­sticas e mÃ©tricas** da coleÃ§Ã£o
* ğŸ¤– **Endpoints para Machine Learning** (features, dataset e prediÃ§Ãµes)
* ğŸ“ˆ **Dashboard de monitoramento** (Streamlit)
* ğŸ“– **DocumentaÃ§Ã£o automÃ¡tica** via Swagger (OpenAPI)

---

## ğŸ—ï¸ Arquitetura

A arquitetura foi pensada para ser simples, modular e extensÃ­vel, permitindo fÃ¡cil evoluÃ§Ã£o para cenÃ¡rios de maior escala.

![Arquitetura do Projeto](diagrama.jpeg)

**Fluxo principal:**

1. IngestÃ£o (scraping simulado ou pipeline externo)
2. Processamento e validaÃ§Ã£o dos dados
3. PersistÃªncia no banco de dados
4. ExposiÃ§Ã£o via API REST
5. Consumo por aplicaÃ§Ãµes, dashboards e pipelines de ML

---

## ğŸ§° Stack TecnolÃ³gica

* **Python 3.12+**
* **Flask** + **Flask-RESTX**
* **SQLite**
* **JWT (JSON Web Token)**
* **Pytest** (testes)
* **Streamlit** (dashboard)
* **Swagger / OpenAPI** (documentaÃ§Ã£o)

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

* Python 3.12 ou superior
* Git
* Poetry **ou** pip + venv

### Clonando o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/books-tech-challenge.git
cd books-tech-challenge
```

### Usando Poetry (recomendado)

```bash
poetry install
poetry shell
```

### Ou usando venv + pip

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate     # Windows
pip install -r requirements.txt
```

---

## ğŸ—„ï¸ Banco de Dados

* O banco **SQLite** Ã© criado automaticamente na primeira execuÃ§Ã£o da API.
* Arquivo gerado: `books.db`

### Popular o banco (scraping simulado)

Endpoint protegido por JWT:

```http
POST /api/v1/scraping/trigger
Authorization: Bearer <ACCESS_TOKEN>
```

---

## â–¶ï¸ Executando a API

```bash
poetry run python api/app.py
```

A API estarÃ¡ disponÃ­vel em:

* **API:** [http://127.0.0.1:5000/api/v1/](http://127.0.0.1:5000/api/v1/)
* **Swagger UI:** [http://127.0.0.1:5000/api/v1/](http://127.0.0.1:5000/api/v1/)

---

## ğŸ” AutenticaÃ§Ã£o JWT

### Login

```http
POST /api/v1/auth/login
Content-Type: application/json
```

```json
{
  "username": "admin",
  "password": "admin123"
}
```

Resposta:

```json
{
  "access_token": "<JWT_ACCESS_TOKEN>",
  "refresh_token": "<JWT_REFRESH_TOKEN>"
}
```

### RenovaÃ§Ã£o de token

```http
POST /api/v1/auth/refresh
Authorization: Bearer <REFRESH_TOKEN>
```

---

## ğŸ“¡ Endpoints da API

### ğŸ“˜ Books

* `GET /api/v1/books/` â€” Lista todos os livros
* `GET /api/v1/books/<id>/` â€” Detalhe de um livro por ID
* `GET /api/v1/books/search/` â€” Busca por tÃ­tulo e/ou categoria
* `GET /api/v1/books/top-rated/` â€” Livros melhor avaliados
* `GET /api/v1/books/price-range/` â€” Filtro por faixa de preÃ§o
* `GET /api/v1/books/stats/` â€” EstatÃ­sticas da coleÃ§Ã£o

### ğŸ—‚ï¸ Categories

* `GET /api/v1/categories/` â€” Lista categorias
* `GET /api/v1/categories/<name>/` â€” Livros por categoria

### â¤ï¸ Health Check

* `GET /api/v1/health/` â€” Status da API e conexÃ£o com o banco

### ğŸ“Š Stats

* `GET /api/v1/stats/overview/` â€” EstatÃ­sticas gerais
* `GET /api/v1/stats/categories/` â€” EstatÃ­sticas por categoria

### ğŸ¤– Machine Learning (opcional)

* `GET /api/v1/ml/features/` â€” Features prontas para anÃ¡lise
* `GET /api/v1/ml/training-data/` â€” Dataset completo
* `POST /api/v1/ml/predictions/` â€” Recebe prediÃ§Ãµes de modelos ML

### ğŸ”’ Scraping (protegido)

* `POST /api/v1/scraping/trigger/` â€” Dispara ingestÃ£o de dados (mock)

---

## ğŸ§ª Testes

Execute todos os testes com:

```bash
pytest
```

---

## ğŸ¤– Machine Learning & Data Science

Os endpoints de ML funcionam como **contrato de dados** para cientistas de dados e pipelines automatizados:

* Features prontas para exploraÃ§Ã£o
* Dataset estruturado para treinamento
* Endpoint de prediÃ§Ã£o para integraÃ§Ã£o com modelos treinados

Esses recursos permitem integraÃ§Ã£o direta com **notebooks**, **pipelines de treinamento** e **ambientes de experimentaÃ§Ã£o**.

---

## ğŸ“Œ ConsideraÃ§Ãµes Finais

Este projeto foi desenvolvido com foco em **engenharia de Machine Learning**, indo alÃ©m de uma API CRUD tradicional. A arquitetura separa claramente ingestÃ£o, persistÃªncia, exposiÃ§Ã£o e consumo de dados, permitindo escalabilidade e evoluÃ§Ã£o futura.

Embora utilize **SQLite** por simplicidade, a estrutura suporta migraÃ§Ã£o para bancos mais robustos e integraÃ§Ã£o com pipelines reais de ingestÃ£o e modelos em produÃ§Ã£o.

A documentaÃ§Ã£o via Swagger, aliada ao uso de JWT e Ã  organizaÃ§Ã£o dos endpoints, torna o projeto adequado para apresentaÃ§Ã£o em contextos profissionais e desafios tÃ©cnicos.

---

ğŸ“„ **LicenÃ§a:** MIT
