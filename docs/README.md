# ğŸ“š Books Tech Challenge

![Python](https://img.shields.io/badge/Python-3.12%2B-blue)
![API](https://img.shields.io/badge/API-Online-success)
![Swagger](https://img.shields.io/badge/Swagger-OpenAPI-brightgreen)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

> ğŸ”— **API pÃºblica:** [https://books-tech-challenge.onrender.com/api/v1/](https://books-tech-challenge.onrender.com/api/v1/)

> ğŸ“Š **Dashboard pÃºblico:** [https://books-tech-challenge.onrender.com/api/v1/](https://books-tech-dashboard.onrender.com)

API RESTful para ingestÃ£o, persistÃªncia e exposiÃ§Ã£o de dados de livros, com foco em **engenharia de dados** e **Machine Learning**. O projeto demonstra boas prÃ¡ticas de arquitetura, documentaÃ§Ã£o e seguranÃ§a, estando preparado para evoluÃ§Ã£o em ambientes de produÃ§Ã£o.

---

## âœ¨ VisÃ£o Geral

O **Books Tech Challenge** Ã© uma API desenvolvida em **Python** com **Flask** e **Flask-RESTX**, responsÃ¡vel por fornecer dados de uma coleÃ§Ã£o fictÃ­cia de livros. A soluÃ§Ã£o cobre todo o ciclo de dados â€” da ingestÃ£o (scraping simulado) ao consumo por aplicaÃ§Ãµes, dashboards e pipelines de Machine Learning.

### Principais funcionalidades

* ğŸ“¥ **IngestÃ£o de dados** (scraping simulado)
* ğŸ—„ï¸ **PersistÃªncia** em banco SQLite
* ğŸ” **AutenticaÃ§Ã£o JWT** para rotas sensÃ­veis
* ğŸ“Š **EstatÃ­sticas e mÃ©tricas** da coleÃ§Ã£o
* ğŸ¤– **Endpoints para Machine Learning** (features, dataset e prediÃ§Ãµes)
* ğŸ“ˆ **Dashboard de monitoramento** (Streamlit)
* ğŸ“– **DocumentaÃ§Ã£o automÃ¡tica** via Swagger (OpenAPI)

---

## ğŸŒ Ambiente PÃºblico (API Online)

O projeto estÃ¡ disponÃ­vel publicamente, permitindo **demonstraÃ§Ã£o tÃ©cnica, testes e avaliaÃ§Ã£o de arquitetura**, sem necessidade de execuÃ§Ã£o local.

* **Base URL da API:**
  [https://books-tech-challenge.onrender.com/api/v1/](https://books-tech-challenge.onrender.com/api/v1/)

* **Swagger UI (DocumentaÃ§Ã£o Interativa):**
  [https://books-tech-challenge.onrender.com/api/v1/](https://books-tech-challenge.onrender.com/api/v1/)

* **URL pÃºblica do Dashboard:**
  [https://books-tech-dashboard.onrender.com/](https://books-tech-dashboard.onrender.com)

> â„¹ï¸ Tanto a API quanto o dashboard utilizam infraestrutura gratuita (Render).
Em perÃ­odos de inatividade, pode ocorrer cold start, fazendo com que a primeira requisiÃ§Ã£o leve alguns segundos.

---

## âš¡ Quick Test

Teste a API diretamente pelo navegador ou via `curl`:

```bash
curl https://books-tech-challenge.onrender.com/api/v1/books/
```

Ou acesse o Swagger e execute as requisiÃ§Ãµes pela interface grÃ¡fica.

Teste o Dashboard pelo navegador

```arduino
https://books-tech-dashboard.onrender.com/
```

---

## ğŸ—ï¸ Arquitetura

A arquitetura foi pensada para ser simples, modular e extensÃ­vel, permitindo fÃ¡cil evoluÃ§Ã£o para cenÃ¡rios de maior escala e integraÃ§Ã£o com pipelines de dados e Machine Learning.

![Arquitetura do Projeto](diagramaPipeline.png)

**Fluxo principal:**

1. IngestÃ£o (scraping simulado ou pipeline externo)
2. Processamento e validaÃ§Ã£o dos dados
3. PersistÃªncia no banco de dados
4. ExposiÃ§Ã£o via API REST
5. Consumo por aplicaÃ§Ãµes, dashboards e pipelines de ML

---

## ğŸ§° Stack TecnolÃ³gica

* **Python 3.12+**
* **Flask** + **Flask-RESTX**
* **SQLite**
* **JWT (JSON Web Token)**
* **Pytest** (testes)
* **Streamlit** (dashboard)
* **Swagger / OpenAPI** (documentaÃ§Ã£o)

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o (Local)

### PrÃ©-requisitos

* Python 3.12 ou superior
* Git
* Poetry **ou** pip + venv

### Clonando o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/books-tech-challenge.git
cd books-tech-challenge
```

### Usando Poetry (recomendado)

```bash
poetry install
poetry shell
```

### Ou usando venv + pip

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate     # Windows
pip install -r requirements.txt
```

---

## â–¶ï¸ Executando a API Localmente

```bash
poetry run python api/app.py
```

A API estarÃ¡ disponÃ­vel em:

* **API:** [http://127.0.0.1:5000/api/v1/](http://127.0.0.1:5000/api/v1/)
* **Swagger UI:** [http://127.0.0.1:5000/api/v1/](http://127.0.0.1:5000/api/v1/)

---

## â–¶ï¸ Executando o Dashboard Localmente

```bash
streamlit run dashboard/app.py
```

O Dashboard estarÃ¡ disponÃ­vel em:

```arduino
http://localhost:8501
```

---

## ğŸ—„ï¸ Banco de Dados

* O banco **SQLite** Ã© criado automaticamente na primeira execuÃ§Ã£o da API
* Arquivo gerado: `books.db`

### Popular o banco (scraping simulado)

Endpoint protegido por JWT:

```http
POST /api/v1/scraping/trigger
Authorization: Bearer <ACCESS_TOKEN>
```

---

## ğŸ” AutenticaÃ§Ã£o JWT

### Login

```http
POST /api/v1/auth/login
Content-Type: application/json
```

```json
{
  "username": "admin",
  "password": "admin123"
}
```

### RenovaÃ§Ã£o de token

```http
POST /api/v1/auth/refresh
Authorization: Bearer <REFRESH_TOKEN>
```

---

## ğŸ“¡ Endpoints da API

### ğŸ“˜ Books

* `GET /api/v1/books/` â€” Lista todos os livros
* `GET /api/v1/books/<id>/` â€” Detalhe de um livro por ID
* `GET /api/v1/books/search/` â€” Busca por tÃ­tulo e/ou categoria
* `GET /api/v1/books/top-rated/` â€” Livros melhor avaliados
* `GET /api/v1/books/price-range/` â€” Filtro por faixa de preÃ§o
* `GET /api/v1/books/stats/` â€” EstatÃ­sticas da coleÃ§Ã£o

### ğŸ—‚ï¸ Categories

* `GET /api/v1/categories/` â€” Lista categorias
* `GET /api/v1/categories/<name>/` â€” Livros por categoria

### â¤ï¸ Health Check

* `GET /api/v1/health/` â€” Status da API e conexÃ£o com o banco

### ğŸ“Š Stats

* `GET /api/v1/stats/overview/` â€” EstatÃ­sticas gerais
* `GET /api/v1/stats/categories/` â€” EstatÃ­sticas por categoria

### ğŸ¤– Machine Learning (opcional)

* `GET /api/v1/ml/features/` â€” Features prontas para anÃ¡lise
* `GET /api/v1/ml/training-data/` â€” Dataset completo
* `POST /api/v1/ml/predictions/` â€” Recebe prediÃ§Ãµes de modelos ML

### ğŸ”’ Scraping (protegido)

* `POST /api/v1/scraping/trigger/` â€” Dispara ingestÃ£o de dados (mock)

---

## ğŸ§ª Testes

```bash
pytest
```

---

## ğŸ¤– Machine Learning & Data Science

Os endpoints de ML funcionam como **contrato de dados** para cientistas de dados e pipelines automatizados:

* Features prontas para exploraÃ§Ã£o
* Dataset estruturado para treinamento
* Endpoint de prediÃ§Ã£o para integraÃ§Ã£o com modelos treinados

Esses recursos permitem integraÃ§Ã£o direta com **notebooks**, **pipelines de treinamento** e **ambientes de experimentaÃ§Ã£o**.

---

## ğŸ“Œ ConsideraÃ§Ãµes Finais

Este projeto foi desenvolvido com foco em **engenharia de Machine Learning**, indo alÃ©m de uma API CRUD tradicional. A arquitetura separa claramente ingestÃ£o, persistÃªncia, exposiÃ§Ã£o e consumo de dados, permitindo escalabilidade e evoluÃ§Ã£o futura.

Embora utilize **SQLite** por simplicidade, a estrutura suporta migraÃ§Ã£o para bancos mais robustos e integraÃ§Ã£o com pipelines reais de ingestÃ£o e modelos em produÃ§Ã£o.

A disponibilidade de um **ambiente pÃºblico**, aliada Ã  documentaÃ§Ã£o via **Swagger**, autenticaÃ§Ã£o **JWT**, organizaÃ§Ã£o arquitetural, alÃ©m de um Dashboard pÃºblico, torna este projeto completo e com excelente maturidade tÃ©cnica.

---

ğŸ“„ **LicenÃ§a:** MIT
