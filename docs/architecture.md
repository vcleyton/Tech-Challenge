# ğŸ—ï¸ Plano Arquitetural â€” Books Tech Challenge

Este documento descreve a arquitetura do **Books Tech Challenge**, detalhando o pipeline de dados, os componentes do sistema, as decisÃµes arquiteturais e os cenÃ¡rios de evoluÃ§Ã£o para **Machine Learning** e **escala em produÃ§Ã£o**.

---

## 1. ğŸ¯ VisÃ£o Geral

O **Books Tech Challenge** Ã© uma API de consulta de livros construÃ­da em **Python (Flask)**, projetada para suportar todo o ciclo de vida dos dados:

* **IngestÃ£o** (scraping ou fontes externas)
* **Processamento e validaÃ§Ã£o**
* **PersistÃªncia em banco de dados**
* **ExposiÃ§Ã£o via API REST**
* **Consumo por aplicaÃ§Ãµes, dashboards e pipelines de ML**

A arquitetura prioriza **modularidade**, **clareza** e **facilidade de evoluÃ§Ã£o**, permitindo que cada componente seja substituÃ­do ou escalado de forma independente.

---

## 2. ğŸ”„ Pipeline de Dados

O pipeline abaixo representa o fluxo completo da soluÃ§Ã£o, desde a origem dos dados atÃ© o consumo final:

```
+------------------+    +---------------------+    +---------------------+    +------------------+
|  Scraping /      | -> | Processamento &     | -> | Banco de Dados      | -> | API REST         |
|  IngestÃ£o        |    | Limpeza de Dados    |    | (SQLite / SQL)     |    | (Flask)          |
+------------------+    +---------------------+    +---------------------+    +------------------+
                                                                              |
                                                                              v
                                                                     +------------------+
                                                                     | Consumidores     |
                                                                     | - Dashboards     |
                                                                     | - Cientistas ML  |
                                                                     | - ServiÃ§os       |
                                                                     +------------------+
```

### DescriÃ§Ã£o do Fluxo

1. **IngestÃ£o / Scraping**

   * Coleta dados de livros (tÃ­tulo, preÃ§o, categoria, rating, disponibilidade).
   * Atualmente simulado para controle de escopo, mas preparado para scraping real ou integraÃ§Ã£o externa.

2. **Processamento e Limpeza**

   * NormalizaÃ§Ã£o de campos.
   * ConversÃ£o de tipos (ex.: preÃ§o, rating).
   * Tratamento de valores inconsistentes.

3. **Banco de Dados**

   * PersistÃªncia estruturada dos dados.
   * Uso inicial de **SQLite**, com fÃ¡cil migraÃ§Ã£o para bancos relacionais mais robustos.

4. **API REST**

   * ExposiÃ§Ã£o dos dados via endpoints organizados por domÃ­nio.
   * DocumentaÃ§Ã£o automÃ¡tica via Swagger.

5. **Consumo**

   * Acesso por dashboards analÃ­ticos.
   * IntegraÃ§Ã£o com pipelines de Machine Learning.
   * Consumo por serviÃ§os externos.

---

## 3. ğŸ§© Componentes do Sistema

* **IngestÃ£o / Scraping**

  * ResponsÃ¡vel pela coleta de dados.
  * Executado via endpoint protegido por JWT.

* **Camada de Processamento**

  * ResponsÃ¡vel por validaÃ§Ã£o e transformaÃ§Ã£o dos dados.
  * Isolada da camada de API.

* **Banco de Dados**

  * Armazena os dados tratados.
  * Projetado para ser facilmente substituÃ­vel.

* **API REST (Flask)**

  * Organizada em namespaces:

    * Books
    * Categories
    * Stats
    * Machine Learning
    * Auth
    * Scraping

* **Camada de Consumo**

  * Dashboards (Streamlit, Grafana).
  * Cientistas de dados e pipelines automatizados.

---

## 4. ğŸ“ˆ Arquitetura para Escalabilidade

Embora a implementaÃ§Ã£o atual seja simples, a arquitetura foi desenhada para crescimento:

* **Banco de dados escalÃ¡vel**

  * MigraÃ§Ã£o direta para PostgreSQL ou MySQL.

* **ServiÃ§os desacoplados**

  * Scraping, API e ML podem se tornar microserviÃ§os independentes.

* **Processamento assÃ­ncrono**

  * Uso de filas (Celery + RabbitMQ ou Kafka) para ingestÃ£o e tarefas pesadas.

* **Cache**

  * Redis ou Memcached para acelerar consultas frequentes.

* **SeguranÃ§a**

  * AutenticaÃ§Ã£o JWT para proteÃ§Ã£o de rotas sensÃ­veis.
  * PossÃ­vel integraÃ§Ã£o com OAuth2 ou Identity Providers.

---

## 5. ğŸ¤– CenÃ¡rio de Uso para Cientistas de Dados / ML

A API fornece **contratos de dados claros** para uso em Machine Learning:

### Acesso a Features

* `GET /api/v1/ml/features`
* Retorna apenas colunas numÃ©ricas e indicadores prontos para modelagem.

### Dataset Completo

* `GET /api/v1/ml/training-data`
* Retorna todos os dados necessÃ¡rios para treinamento e anÃ¡lise exploratÃ³ria.

### Envio de PrediÃ§Ãµes

* `POST /api/v1/ml/predictions`
* Recebe resultados de modelos treinados para anÃ¡lises ou ciclos de feedback.

### Fluxo tÃ­pico de ML

```
API -> Features -> Treinamento do Modelo -> PrediÃ§Ãµes -> MÃ©tricas / Feedback
```

---

## 6. ğŸ”Œ Plano de IntegraÃ§Ã£o com Modelos de Machine Learning

### Exemplo de Features

```json
[
  {
    "price": 12.99,
    "rating": 5,
    "available": 1
  }
]
```

### Dataset Completo

```json
[
  {
    "id": 1,
    "title": "Clean Code",
    "price": 12.99,
    "rating": 5,
    "availability": "In stock",
    "category": "Programming",
    "image_url": "url",
    "product_url": "url"
  }
]
```

### Envio de PrediÃ§Ãµes

```json
[
  {
    "id": 1,
    "predicted_rating": 4.8
  }
]
```

### EvoluÃ§Ãµes Futuras

* Treinamento de modelos diretamente a partir da API.
* OrquestraÃ§Ã£o de pipelines com Airflow ou Prefect.
* Dashboards analÃ­ticos com Streamlit ou Grafana.
* Monitoramento de performance de modelos (MLOps).

---

## 7. ğŸ“Œ ConsideraÃ§Ãµes Finais

* Arquitetura **modular e extensÃ­vel**.
* Pipeline completo: ingestÃ£o â†’ processamento â†’ persistÃªncia â†’ API â†’ consumo.
* Preparada para **Machine Learning** e evoluÃ§Ã£o para produÃ§Ã£o.
* SeguranÃ§a, observabilidade e escalabilidade consideradas desde o design.

Este plano arquitetural garante que o projeto nÃ£o seja apenas funcional, mas tambÃ©m **sustentÃ¡vel, profissional e pronto para crescimento**.
